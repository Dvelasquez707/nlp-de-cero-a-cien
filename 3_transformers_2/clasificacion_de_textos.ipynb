{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ec711e-2392-4c8c-b85f-4f2ef6f17414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e2afa1-ce7d-4ff5-88ff-5c455bf0e5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_reviews_multi (/home/lewis/.cache/huggingface/datasets/amazon_reviews_multi/es/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 200000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"amazon_reviews_multi\", \"es\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57e5ef95-2a77-4af3-85f9-0413fd356dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/lewis/.cache/huggingface/datasets/amazon_reviews_multi/es/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-e32eb148007d7067.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42).select(range(20_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff25c30-89b9-4eb7-badc-028fc272c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    \"From: https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb\"\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e20b3e-d5df-45eb-a4db-b8082ff82b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_0727973</td>\n",
       "      <td>product_es_0688938</td>\n",
       "      <td>reviewer_es_0468676</td>\n",
       "      <td>1</td>\n",
       "      <td>SOIS UNOS HDP me mandasteis un produccto que no era el que estabais vendiendo. Un p8 lite me mandais en vez del que vendeis.</td>\n",
       "      <td>ESTAFA</td>\n",
       "      <td>es</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_0806549</td>\n",
       "      <td>product_es_0547116</td>\n",
       "      <td>reviewer_es_0470608</td>\n",
       "      <td>3</td>\n",
       "      <td>Muy basico y calidad media</td>\n",
       "      <td>Carraca</td>\n",
       "      <td>es</td>\n",
       "      <td>home_improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es_0141795</td>\n",
       "      <td>product_es_0142033</td>\n",
       "      <td>reviewer_es_0644301</td>\n",
       "      <td>5</td>\n",
       "      <td>Se ajusta al producto descrito. Muy buena relación caludad-precio</td>\n",
       "      <td>Buen producto</td>\n",
       "      <td>es</td>\n",
       "      <td>toy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es_0051189</td>\n",
       "      <td>product_es_0865715</td>\n",
       "      <td>reviewer_es_0253018</td>\n",
       "      <td>4</td>\n",
       "      <td>De momento bien, espero que me dure</td>\n",
       "      <td>Buen montaje</td>\n",
       "      <td>es</td>\n",
       "      <td>home_improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es_0042184</td>\n",
       "      <td>product_es_0643491</td>\n",
       "      <td>reviewer_es_0978177</td>\n",
       "      <td>4</td>\n",
       "      <td>Acorde con las especificaciones</td>\n",
       "      <td>Buen precio / calidad</td>\n",
       "      <td>es</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>es_0403162</td>\n",
       "      <td>product_es_0441084</td>\n",
       "      <td>reviewer_es_0939490</td>\n",
       "      <td>4</td>\n",
       "      <td>El kit es muy completo, el soporte del fabricante es sobresaliente. Muy fácil de instalar por lo completa que viene la pantalla, sus accesorios y sus instrucciones.</td>\n",
       "      <td>Kit completo y de fácil instalación</td>\n",
       "      <td>es</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>es_0136866</td>\n",
       "      <td>product_es_0137431</td>\n",
       "      <td>reviewer_es_0487268</td>\n",
       "      <td>3</td>\n",
       "      <td>Un corre pasillos muy económico pero con poca estabilidad si el niño/niña no sabe andar aún. Las ruedas traseras deberían estar más abiertas o ser más gruesas</td>\n",
       "      <td>Bien pero mejorable</td>\n",
       "      <td>es</td>\n",
       "      <td>toy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>es_0360088</td>\n",
       "      <td>product_es_0986734</td>\n",
       "      <td>reviewer_es_0234926</td>\n",
       "      <td>4</td>\n",
       "      <td>Es un cortador de piña que la verdad es muy práctico y fácil de usar, tan sólo dar unas vueltas hasta llegar hasta la parte de abajo de la piña y tirar hacia arriba y ya salen todas las rodajas listas para comer.El cortador viene un poco sucio pero sólo es polvo se lava y ya está.</td>\n",
       "      <td>Juanma</td>\n",
       "      <td>es</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>es_0123657</td>\n",
       "      <td>product_es_0016289</td>\n",
       "      <td>reviewer_es_0734531</td>\n",
       "      <td>3</td>\n",
       "      <td>Todo lo que llevo afilado hasta el momento me lo ha dejado de maravilla.</td>\n",
       "      <td>Esta bastante bien</td>\n",
       "      <td>es</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>es_0765509</td>\n",
       "      <td>product_es_0752738</td>\n",
       "      <td>reviewer_es_0806997</td>\n",
       "      <td>2</td>\n",
       "      <td>La devolvi porque mi hija de nueve meses no cabia, literalmente, en el asiento, las medidas en si son más justitas que otras tronas, nosotros ibamos buscando una que nos durara un tiempo.</td>\n",
       "      <td>pequeña</td>\n",
       "      <td>es</td>\n",
       "      <td>baby_product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d8facc-f0c7-421d-9649-f37b117c9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ce0be23-e68e-46af-bca1-d215576fb779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[\"train\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb2b178e-2cbe-423c-93b6-88836c85b096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_0614019</td>\n",
       "      <td>product_es_0489972</td>\n",
       "      <td>reviewer_es_0452711</td>\n",
       "      <td>3</td>\n",
       "      <td>La montarlo se rompió una rueda debido a mater...</td>\n",
       "      <td>.</td>\n",
       "      <td>es</td>\n",
       "      <td>furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_0106878</td>\n",
       "      <td>product_es_0192285</td>\n",
       "      <td>reviewer_es_0332773</td>\n",
       "      <td>2</td>\n",
       "      <td>El servicio ha sido muy bueno, me ha llegado 2...</td>\n",
       "      <td>Primeras impresiones</td>\n",
       "      <td>es</td>\n",
       "      <td>pc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es_0894107</td>\n",
       "      <td>product_es_0849920</td>\n",
       "      <td>reviewer_es_0811760</td>\n",
       "      <td>5</td>\n",
       "      <td>Funciona genial y la llevo conmigo en todas la...</td>\n",
       "      <td>.</td>\n",
       "      <td>es</td>\n",
       "      <td>camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es_0611608</td>\n",
       "      <td>product_es_0261733</td>\n",
       "      <td>reviewer_es_0873700</td>\n",
       "      <td>4</td>\n",
       "      <td>Me ha encantado el olor, pero se va a la media...</td>\n",
       "      <td>Olor excelente</td>\n",
       "      <td>es</td>\n",
       "      <td>beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es_0374593</td>\n",
       "      <td>product_es_0528114</td>\n",
       "      <td>reviewer_es_0342501</td>\n",
       "      <td>5</td>\n",
       "      <td>Muy divertida y se ajusta a la descripción. En...</td>\n",
       "      <td>Envío rápido</td>\n",
       "      <td>es</td>\n",
       "      <td>toy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id          product_id          reviewer_id  stars  \\\n",
       "0  es_0614019  product_es_0489972  reviewer_es_0452711      3   \n",
       "1  es_0106878  product_es_0192285  reviewer_es_0332773      2   \n",
       "2  es_0894107  product_es_0849920  reviewer_es_0811760      5   \n",
       "3  es_0611608  product_es_0261733  reviewer_es_0873700      4   \n",
       "4  es_0374593  product_es_0528114  reviewer_es_0342501      5   \n",
       "\n",
       "                                         review_body          review_title  \\\n",
       "0  La montarlo se rompió una rueda debido a mater...                     .   \n",
       "1  El servicio ha sido muy bueno, me ha llegado 2...  Primeras impresiones   \n",
       "2  Funciona genial y la llevo conmigo en todas la...                     .   \n",
       "3  Me ha encantado el olor, pero se va a la media...        Olor excelente   \n",
       "4  Muy divertida y se ajusta a la descripción. En...          Envío rápido   \n",
       "\n",
       "  language product_category  \n",
       "0       es        furniture  \n",
       "1       es               pc  \n",
       "2       es           camera  \n",
       "3       es           beauty  \n",
       "4       es              toy  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab53e911-2374-4ed9-8763-8824ab105d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    4065\n",
       "4    4045\n",
       "3    4032\n",
       "1    3960\n",
       "2    3898\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"stars\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe2083-e959-446a-a831-90139c8ebbe4",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aa254bb-162f-44e4-9b40-595a90ad220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_checkpoint = \"bertin-project/bertin-roberta-base-spanish\"\n",
    "model_checkpoint = \"BSC-TeMU/roberta-base-bne\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55cfde4b-6b30-4942-b664-fdb86af23ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50262"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e3fb069-14cd-4d01-814c-be1434d8b130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8edd6d92-bc62-4bfc-bebf-0ce4713dfa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <s>\n",
      "1465 ¡\n",
      "12616 hola\n",
      "66 ,\n",
      "503  me\n",
      "17111  llamo\n",
      "532  le\n",
      "19514 wis\n",
      "55 !\n",
      "2 </s>\n"
     ]
    }
   ],
   "source": [
    "encoded_str = tokenizer.encode(\"¡hola, me llamo lewis!\")\n",
    "\n",
    "for token in encoded_str:\n",
    "    print(token, tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3a5337-be51-4b63-a48f-d84469ea63e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.9.2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5ab78b5-f8d7-4701-98d5-42a7bb9cc677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples[\"review_body\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50afcb76-51f0-4691-900f-74e9ed6e5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc083152-d33e-4215-aa55-6c0f34843014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset = dataset[\"train\"].train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48c07922-100f-40b5-8b45-87448bde2f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/lewis/.cache/huggingface/datasets/amazon_reviews_multi/es/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-5891b043fe5d9345.arrow\n",
      "Loading cached processed dataset at /home/lewis/.cache/huggingface/datasets/amazon_reviews_multi/es/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-82c7b30bde2d5822.arrow\n",
      "Loading cached processed dataset at /home/lewis/.cache/huggingface/datasets/amazon_reviews_multi/es/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-5b22c1fadf14e8e7.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'language', 'product_category', 'product_id', 'review_body', 'review_id', 'review_title', 'reviewer_id', 'stars'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'language', 'product_category', 'product_id', 'review_body', 'review_id', 'review_title', 'reviewer_id', 'stars'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'language', 'product_category', 'product_id', 'review_body', 'review_id', 'review_title', 'reviewer_id', 'stars'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(tokenize_text, batched=True)\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "206910b1-9258-49e7-987b-56401875833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_labels(examples):\n",
    "    if examples[\"stars\"] > 3:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    return {\"labels\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac4baf8b-e8a6-4dee-a81a-ea0fe0d73264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/lewis/.cache/huggingface/datasets/amazon_reviews_multi/es/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-7443381e9b27829a.arrow\n",
      "Loading cached processed dataset at /home/lewis/.cache/huggingface/datasets/amazon_reviews_multi/es/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-3dac11b4268fb4d2.arrow\n",
      "Loading cached processed dataset at /home/lewis/.cache/huggingface/datasets/amazon_reviews_multi/es/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-ba621aa6467e4a29.arrow\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = encoded_dataset.map(binarize_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cc0febf-8e42-4c19-b12b-83ff86b52223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_mapping = {idx+1: idx for idx in range(5)}\n",
    "# label_mapping\n",
    "\n",
    "# encoded_dataset = encoded_dataset.map(lambda x: {\"labels\": label_mapping[x[\"stars\"]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff98a5b1-6415-4d7e-ba47-7d89ce7ebfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at BSC-TeMU/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at BSC-TeMU/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels = 2\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dd33664-e1ef-43cc-b445-e13b12aa48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_dataset.set_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "523465d1-059c-4c18-a313-8b41f79c527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(**encoded_dataset[\"train\"][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4ebab1c-893c-4eb9-8f51-9e55c6596463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\") \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75fc4131-7a48-42bb-b9a7-f8df40a05aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 16\n",
    "logging_steps = len(encoded_dataset[\"train\"]) // batch_size\n",
    "training_args = TrainingArguments(output_dir=\"results\",\n",
    "                                  num_train_epochs=5,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\",\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\", \n",
    "                                 logging_steps=logging_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c115807-61e9-4ba2-a100-df2ac2266767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: language, product_category, reviewer_id, review_title, review_id, review_body, product_id, stars.\n",
      "***** Running training *****\n",
      "  Num examples = 20000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3125\n",
      "/home/lewis/miniconda3/envs/hf/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 10:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.286933</td>\n",
       "      <td>0.882400</td>\n",
       "      <td>0.882042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.266500</td>\n",
       "      <td>0.351466</td>\n",
       "      <td>0.882400</td>\n",
       "      <td>0.881722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.266500</td>\n",
       "      <td>0.433992</td>\n",
       "      <td>0.873800</td>\n",
       "      <td>0.874459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.581961</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.876932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.677518</td>\n",
       "      <td>0.872400</td>\n",
       "      <td>0.872072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: language, product_category, reviewer_id, review_title, review_id, review_body, product_id, stars.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to results/checkpoint-625\n",
      "Configuration saved in results/checkpoint-625/config.json\n",
      "Model weights saved in results/checkpoint-625/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-625/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-625/special_tokens_map.json\n",
      "/home/lewis/miniconda3/envs/hf/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: language, product_category, reviewer_id, review_title, review_id, review_body, product_id, stars.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to results/checkpoint-1250\n",
      "Configuration saved in results/checkpoint-1250/config.json\n",
      "Model weights saved in results/checkpoint-1250/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-1250/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-1250/special_tokens_map.json\n",
      "/home/lewis/miniconda3/envs/hf/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: language, product_category, reviewer_id, review_title, review_id, review_body, product_id, stars.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to results/checkpoint-1875\n",
      "Configuration saved in results/checkpoint-1875/config.json\n",
      "Model weights saved in results/checkpoint-1875/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-1875/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-1875/special_tokens_map.json\n",
      "/home/lewis/miniconda3/envs/hf/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: language, product_category, reviewer_id, review_title, review_id, review_body, product_id, stars.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to results/checkpoint-2500\n",
      "Configuration saved in results/checkpoint-2500/config.json\n",
      "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-2500/special_tokens_map.json\n",
      "/home/lewis/miniconda3/envs/hf/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: language, product_category, reviewer_id, review_title, review_id, review_body, product_id, stars.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to results/checkpoint-3125\n",
      "Configuration saved in results/checkpoint-3125/config.json\n",
      "Model weights saved in results/checkpoint-3125/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-3125/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-3125/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-625 (score: 0.8820420450224683).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3125, training_loss=0.1422505355834961, metrics={'train_runtime': 645.8102, 'train_samples_per_second': 154.844, 'train_steps_per_second': 4.839, 'total_flos': 6779138563555200.0, 'train_loss': 0.1422505355834961, 'epoch': 5.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=encoded_dataset[\"train\"],\n",
    "                  eval_dataset=encoded_dataset[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c503d0d-699a-4f26-a093-bea61f03d3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: language, product_category, reviewer_id, review_title, review_id, review_body, product_id, stars.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 32\n",
      "/home/lewis/miniconda3/envs/hf/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2728419899940491,\n",
       " 'eval_accuracy': 0.8878,\n",
       " 'eval_f1': 0.8876700706373296,\n",
       " 'eval_runtime': 9.0253,\n",
       " 'eval_samples_per_second': 553.996,\n",
       " 'eval_steps_per_second': 17.395,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(encoded_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b5e20-fda5-4805-bb26-e8f87e7dde00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
