{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ec711e-2392-4c8c-b85f-4f2ef6f17414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e2afa1-ce7d-4ff5-88ff-5c455bf0e5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset muchocine (/home/lewis/.cache/huggingface/datasets/muchocine/default/1.1.1/3ed5582584cd84ef722606a3d725ef18fd4647d63195fef05c47683e5a056ccd)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"muchocine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df6623e-1dbc-4baf-94a8-6e844303075c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review_body', 'review_summary', 'star_rating'],\n",
       "        num_rows: 3872\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129f9f6d-0980-40b5-bbd2-0a8a5291be01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_body': '\"May, ¿Quieres ser mi amigo?\" es una de esas películas que nos recuerdan que el terror no siempre lleva garras de acero en una mano o una mascara en la cara. El terror y la locura se encuentran mucho más cerca de nosotros, de la realidad, de nuestra pacífica y hasta a veces aburrida monotonía. May funciona bajo el método: la bestia duerme dentro de nosotros. En cada uno de nosotros hay un posible psicópata y nuestra vecina la del segundo puede ocultar un oscuro pasado o una doble vida. Para ello, Lucky McKee, nos narra efectivamente una historia presuntamente cotidiana (que sin embargo, engancha desde el principio) sobre una joven muy parecida a esas otras tantas que pululan a nuestro alrededor. La rarita de la clase, la niña tímida de la tienda de comestibles, esa extraña hermana de nuestro amigo, nuestra prima la del pueblo. Es por esto que nos montamos en un tren de cercanías y no en un tren de alta velocidad con escenas más vistas que las reposiciones de \"El Principe de Bell Air\" y adolescentes lelos e insoportables con superávit de hormonas y déficit de neuronas. En este tren nos encontramos con personajes bien trazados y de carne y hueso. Personajes trabajados, atractivos e incluso muy atrevidos. (La compañera de May en el veterinario en donde trabaja no tiene desperdicio) Todos ellos giran en torno al personaje de May, interpretado con muchísimo mimo y talento por Angela Bettis que logra crear un personaje que se nos muestra irresistible y original. La trama es como digo muy interesante y nos sorprende por llevar un ritmo que rompe nuestras expectativas pero que nunca nos defrauda. La transformación que sufre May y la irremediable desencadenación hacia un destino sobrecogedor, sucede por culpa de toda una serie de características y acontecimientos muy bien explicados y calculadamente reconocibles que forjan y maduran la verdadera cara del terror.Esta es una película que coge carrerilla para empezar antes de donde empiezan casi todas las demás de su género, para después acabar además bastante más allá de donde se atrevería ninguna otra. En su día Todd Solondz, conocido por lograr llegar también muy lejos con sus saltos y por rehuir de los géneros habituales para inventarse los suyos propios, nos regaló \"Bienvenidos a la casa de muñecas\" (1996), (película anterior a su ácida y genial \"Happyness\" (1998) que tiene mucho que ver con esta. En ella, el señor Solondz, abordaba de forma cruda y valiente, el drama de una niña fea y traumatizada, enfrentada a la más cruda realidad. La mayor diferencia entre ellas es, por supuesto, que aquella no era una película de terror. Bueno, y al grano, que no esperéis escenas convencionales, ni gatos que se empeñan en perderse, ni sustitos efectistas, ni tampoco efectos especiales porque no hacen falta. Esta es una producción de bajo presupuesto pero además no se nota. Y no se nota, porque tiene una mucho más que correcta fotografía, una atmósfera angustiosa y embriagadora, un montaje inteligente y un final muy verdadero, y por esto mismo, aterradoramente real.Esta es una peli que merece la pena, (de notable alto para quien ahora os escribe) y es que, amigos, si \"Amelie\" hubiese sido una película de terror en vez de un mágico cuento, aquella dulce francesita se hubiera llamado sin duda \"May\". ¿Y la magia?, La magia negra, por supuesto, muy negra. ',\n",
       " 'review_summary': 'May, ¿quieres ser mi amigo? ',\n",
       " 'star_rating': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff25c30-89b9-4eb7-badc-028fc272c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    \"From: https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb\"\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e20b3e-d5df-45eb-a4db-b8082ff82b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tras la nefasta El Reino de los Cielos, y la sensiblera Un Buen Año, llega American Gangster, la que para muchos es última oportunidad para un Ridley Scott que lleva dando tumbos desde hace muchos años. Entre medias, una nueva edición de Blade Runner, la que a todas luces parece la definitiva, al menos hasta dentro de unos años.Hay que decir de American Gangster que los temas que trata prometen, a pesar de sonar a algo ya conocido por el espectador. No es la primera vez que se retrata en la gran pantalla la corrupción policial en una gran ciudad como Nueva York en los años setenta, ni el auge de las drogas, ni menos aún el ascenso y caida de un gangster. Pero a pesar de ello, Ridley Scott consigue tejer una trama intensa y llena de emoción que atrapa por completo al espectador. El film avanza a buen ritmo, Scott no se recrea en la narración, y la mejor prueba de ello es que no se hace pesado ni aburrido a pesar de su largo metraje. El cineasta británico ofrece no sólo el retrato de un gangster lleno de carisma (excepcional Denzel Washington) y el policía que le persigue (un no menos brillante Russell Crowe), sino que muestra al mismo tiempo las convulsiones que azotaban a todo un país: la pobreza, la miseria, la corrupción, la guerra de Vietnam, un profundo desencanto surgido entre la población, todo ello aderezado por el auge en la venta de drogas.Al fin y al cabo, American Gangster viene a ser un espejo en el que se refleja la visión más turbia y distorsionada del tan cacareado sueño americano. Y es que en la tierra de las oportunidades también abunda la miseria, y nada crece mejor entre la miseria como el crimen y la corrupción.</td>\n",
       "      <td>Al fin y al cabo, American Gangster viene a ser un espejo en el que se refleja la visión más turbia y distorsionada del tan cacareado sueño americano.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sylvester Stallone vuelve a ponerse detrás de las cámaras, para ofrecernos una nueva visión del potro italiano, una vez que ya han pasado sus tiempos de gloria, para mostrarnos a la persona, a ese ex boxeador que rememora con nostalgia sus días como campeón.Por supuesto que Sly vuelve a enfundarse los guantes, y pese a sus años, se conserva en plena forma. En esta sexta y última parte de las andanzas de Rocky Balboa, Stallone nos muestra la vida que tiene el que fuese bicampeón de los pesos pesados. Viudo y dirigiendo su restaurante italiano \"Adrian´s\", también nos muestran a Rocky como un padre preocupado, que tiene una seria incomunicación con su hijo, ya que éste se avergüenza de los éxitos de su padre, al tener que soportar una dura losa, la que supone ser el hijo de una celebridad. Como no, los problemas entre ellos se solventarán a la vez que la película llega al punto que nos interesa, cuando Rocky por casualidad, acaba aceptando pelear con el campeón de los pesos pesados Mason Dixon.Todo esto viene precedido de que a Balboa le entra el gusanillo de volver a pelear, cosas pequeñas para sentirse vivo, y como él mismo dice ? Creo que todavía tengo algunas cosas en el sótano ? así que tras ese punto de partida, y gracias a un combate virtual que dan por televisión enfrentando a Rocky y a Mason Dixon, los promotores deciden hacerlo real. Toda una puesta a punto para ambos púgiles.En este momento, es cuando las nostalgias se hacen más evidentes, y cuando se nos enternece el corazón, observando al potro italiano salir por el tunel de vestuarios y escuchar y ver a la multitud congregada gritando el nombre del campeón. Un punto muy interesante, es que la imagen cambia pasando a alta definición, de modo que se nos muestra como la típica retransmisión deportiva, dando así un toque más verídico. El primer round es lo mejor de la película, y es donde afloran todos nuestros sentimientos hacia este personaje que llevamos viendo en tantas películas. A continuación, se nos muestra el resto del combate a modo de videoclip, con un ritmo endiablado que nos traslada hasta el último asalto. En definitiva \"Rocky Balboa\" es un producto digno, para terminar una saga que ha enamorado a millones de espectadores, y que de esta manera se ve recompensada. En ningún momento se nos pretende engañar, ya que todos sabemos lo que nos vamos a encontrar en esta película, y la verdad es que se agradece este gesto.Hasta siempre Rocky.</td>\n",
       "      <td>Es un producto digno, para terminar una saga que ha enamorado a millones de espectadores, y que de esta manera se ve recompensada. En ningún momento se nos pretende engañar, ya que todos sabemos lo que nos vamos a encontrar, y la verdad es que se agradece este gesto.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rara película para nosotros argentinos, que no tenemos tan a la mano los problemas de discriminación racial como algunos países europeos pero no parece casual que aparezca hoy, después del conflicto de los suburbios franceses. De este modo, la película puede interpretarse como una alegoría. Situándonos: ¿qué son los videos? ¿qué papel cumplen y qué pueden representar para esa familia? Los videos son \"la mirada del Otro\". El \"Otro\" nos espía y nos atemoriza, no sabemos desde dónde y qué es lo que ve o lo que vio.El temor surge por el sentimiento de culpa del protagonista y su mujer, que en la alegoría es la sociedad blanca, acomodada y burguesa, frente al \"Otro\", a los marginados de origen africano que viven en los suburbios. El primer indicio lo da la casi pelea callejera con el joven ciclista negro en condiciones de propinarle una paliza al protagonista, quien depués de insultos y bravatas, opta por eludir el pleito con un pedido de disculpas por parte de la esposa. El segundo indicio es la desconfianza del chico blanco hacia su madre. Hay varios otros. Se nota en todo el desarrollo un ambiente asfixiante, cuyo motivo no se ve, como no se ve al \"Otro\" que filma, pero que siempre está presente y su presencia se siente. La familia blanca no quiere que exista el \"Otro\"; la distrae de sus quehaceres, de su vida a la que tiene derecho, la intimida, pero el Estado, la Policía, no la puede ayudar a quitárselo de encima porque.el \"Otro\" no le ha hecho nada. No hay motivos para que intervenga la policía. Si hay un agresor, es el protagonista. Los dibujos recuerdan el conflicto infantil entre el blanco y el argelino, donde hubo un perdidoso y un ganador. El que pierde es el argelino, hijo de quienes vinieron a la Europa de posguerra a trabajar en la reconstrucción y que quedaron allí como kelpers, como ciudadanos de segunda. Esa generación se perdió, no tuvo la educación para la integración económica y el resultado está a la vista en el pequeño y sórdido departamento de Majid, en contraste con la cómoda y fría vivienda de la familia blanca. Majid crió a su hijo sin resentimientos y sin olvido pero no pudo sobrevivir a la depresión de su generación marginada, que vio el progreso, el confort y la cultura?desde afuera. Su muerte se hace efectiva enfrente de su verdugo infantil. Su sangre se mezcla, se confunde con la del gallo que le valió la expulsión de la casa, de la cultura y del progreso. El gallo?el gallo francés que anuncia el mañana, el progreso, el adelanto. muere degollado igual que Majid, cuyos padres fueron sacrificados en el Sena por los blancos durante el conflicto con Argelia. No hubo progreso, no hubo integración para ellos, sólo muerte; el gallo no cantó para ellos. La escena final muestra a los hijos de los protagonistas a la salida del colegio, conversando? Eso podría resolver el enigma de los videos y puede ser un nuevo gallo que canta para ambos, siempre y cuando vayan juntos al colegio; siempre que el Otro deje de ser otro un Otro ajeno, enfrentado, sino que se lo reconozca como parte igualitaria de una sociedad todavía deudora.</td>\n",
       "      <td>Los videos son \"la mirada del Otro\", el \"Otro\" nos espía y nos atemoriza</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Casi como un axioma, las terceras partes de una saga suelen superar, con frecuencia, a las primeras, y siempre a las segundas. Encontramos un referente cercano en El Retorno del Rey. En el Fin del Mundo, decapitada la gallina de los huevos de oro, la manifiesta descompensación existente entre un guión endeble y el virtuosismo técnico que lo acompaña, resulta estrepitosamente evidente. De fondo, la consolidación de unos indefinidos personajes que ya cuentan con nombre propio en la historia del séptimo arte.De las profundidades, emergente,/ El Hidalgo de los Mares/ purga su deuda pendiente/ con El Mundo en Sus Manos,/ amarrando presto el timón,/ ya se atisba en lontananza/ al Temido Burlón/ Su Majestad de los Mares del Sur,/ por todos conocido como El Capitán \"Bloom\"/.Vergüenza ajena que sentiría Espronceda de mí. La misma que arrebolaría a Raoul Walsh (él, que tan bien medía los tiempos) ante el cúmulo de despropósitos apadrinados por el \"genial\" artesano que repite tras las cámaras. ¡Ay si Michael Curtiz alzara la cabeza!. Si Robert Siodmak hubiera contado con la mitad de posibilidades técnicas en su época. Si Jacques Tourneur hubiera dirigido a la Knightley. Si Byron Haskin se llega a encontrar con este pastel. Qué derroche de efectos especiales y qué falta absoluta de imaginación. ¿Habrán oído hablar los guionistas de Borden Chase?Pero vayamos por partes. Los cocoteros aún no dan castañas. Los continuos pactos y traiciones, y la creación de un personaje homosexual, constituyen aciertos innegables del guión. ¡Y nos reencontramos con el perro!, causa de mi única alegría y máxima preocupación.Más que fascinar, La Maldición de la Perla Negra, gratamente, sorprendió. Las aventuras de abordaje eran rescatas de los abismos fílmicos; sus desventuras, volvían a conquistar, y el viraje dado hacia el género fantástico, sin convencer, no llegó a disgustar. De esta manera, asistimos emocionados a la apertura del Hombre del Cofre muerto (¿o era al revés?), que, básicamente, se dedicó a defraudar. Una imperdonable concepción del guión situaba la acción en tres escenarios diferentes, para el lucimiento de sus principales protagonistas y tortura del espectador. Al salir del cine, con el cerebelo hirviente, pocos reconocieron al Capitán Barbossa.. ni a la madre que lo parió.Ésta que suscribe, se negó a soltar amarras y, con la finalidad de evitar un anunciado hundimiento, se dispuso a repasar las ambas dos primeras partes, para no perderse en alta mar. Se perdió y naufragó. Digamos que, En el Fin del Mundo, los guiones no son enrevesados, sino ininteligibles. Con una premeditada confusión, profusión y difusión de ideas, Elliott y Rossio sólo dan opción al disfrute de un producto meramente visual. El impactante inicio se diluye en la brisa de Singapur nada más zarpar, se sumerge en la inmensidad de su propia incongruencia argumental, tímidamente emerge en la esperada Asamblea de Hermanos y, marcando rumbo hacia buen puerto, encuentra un insalvable acantilado al navegar.El catalejo, ahora, permite vislumbrar una efectista espectacularidad sin límites, envuelta en tres horas interminables de metraje, en las que buceamos para sólo hallar una pequeña escena-tesoro, dos imágenes hermosas y tres frases que no me resisto a mencionar.La primera de ellas, enviada al director: \"¿Creéis que lo tiene todo planeado o va improvisando sobre la marcha?\". La segunda, reservada al desenlace: \"El mundo sigue siendo el mismo, pero con menos alicientes\". Y la tercera, que honra a Depp: \"Ninguna causa está perdida mientras quede un insensato dispuesto a luchar por ella\". ¡Pobre Johnny!, objeto principal del homenaje que se realiza a Fantasía. Peor es el ofrecido a La Sirenita, con esa enorme diosa Calipso imitando a la burbuja, digo, a la bruja Úrsula del mar.La escena no es otra que la emersión del Holandés Errante. y su flamante almirante. Las imágenes, una moneda flotante y ese barquito, en un manto de estrellas que, en absoluto silencio, surca la mar. La memoria cinéfila nos arrastra hasta la relajante nave espacial de Kubrick sin vals, y a una precipitada apreciación: En el Fin del Mundo, ¿tampoco se propaga el sonido?.Con respecto al reparto, copio de mis anteriores críticas. Excelente Geoffrey Rush. Orlando, un primor. No sería justo que Jack Sparrow eclipsara al actor, en detrimento de las magníficas interpretaciones obtenidas bajo las órdenes de Tim Burton. Y Keira Knightley, técnicamente perfecta, pero con una alarmante carencia de cloruro de sodio en vena. Añado que el sombrero de china le sienta muy bien, y subrayo las acertadas actuaciones de Stellan Skarsgard (el Goya de Milos Forman) y de Keith Richards (el guitarrista de los Rolling Stones).Y no, no me quedé en el cine para ver la falsa despedida de \"después de\" los títulos de crédito finales. Ésta, que cada semana os piratea el tiempo, se niega a escribir sobre una cuarta parte. Claro que, por 9 reales de a 8.. ¿quién sabe?.</td>\n",
       "      <td>Los cocoteros aún no dan castañas. Los continuos pactos y traiciones, y la creación de un personaje homosexual, constituyen aciertos innegables del guión. ¡Y nos reencontramos con el perro!, causa de mi única alegría y máxima preocupación.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Durante aquellos belicosos años 80 (bien podría ser el título de un recopilatorio de atentados fílmicos en el cine de acción), surgieron una serie de actores que dispararon su popularidad interpretando a toscos heroes de acción, en muchos caso rozando el patriotismo más reaccionario, o en el mejor de los casos, sin tan siquiera resultar patrióticos. Nombres como Steven Seagal, Van Damme, Charles Bronson o Arnold Schwarzenegger se encargaron de demostrarnos que la sutileza no formaba parte de su catálogo de habilidades. Pese a ello, se ganaron el beneplácito del público con productos donde la única baza que jugaban a su favor era un distanciamiento cool de la violencia apelando a los instintos más primarios del ser humano, y por ende, del espectador. Entre todos ellos se encontraba un personaje llamado John Rambo, interpretado por Sylvester Stallone, cuyo primer film, allá por el año 1982, nos mostraba el complicado retorno a casa de los veteranos de la guerra del Vietnam, y su extrema dificultad para adaptarse a la vida diaria, siendo además poco considerados por su propio gobierno. En ese primer film, de nombre \"Acorralado\", se intentaba trazar un eficaz retrato de estos ex-combatientes, y aunque el film era un producto solvente, interesante incluso, se quedaba bastante en la superficie, usando su excusa argumental como pretexto para desarrollar lo que en el fondo interesaba a los participantes de aquel proyecto, la acción pura y dura. Poco más tarde llegarían sus dos secuelas, \"Rambo: Acorralado II\" y \"Rambo III\", siendo ya su argumento un cúmulo de situaciones reaccionarias en su mayoría, al describir de forma peligrosa la intervención del ex soldado en conflictos alejados de su propia competencia. Especialmente sangrante era la tercera parte, donde, en un guiño irónico del destino , el argumento situaba como camaradas de lucha al gobierno americano y a aquel sector extremista que ahora ha supuesto una amenaza para su pujante imperialismo. Todo ello acompañado de una historia repleta de tópicos y chascarillos varios.Veinte años más tarde nos llega el cierre a esta saga, de nuevo interpretada por un Sylvester Stallone necesitado de éxitos inmediatos, y con la esperanza de encontrarnos con un producto cuanto menos respetable después de la correcta \"Rocky Balboa\" (su anterior film, un film respetable y ameno en su desarrollo, bastante satisfactorio sino se acude a él con demasiadas espectativas). En esta ocasión, además, se encarga de dirigir esta \"John Rambo\" (de nombre \"Rambo\" a secas en el mercado americano), un film que recupera una manera de hacer cine de acción perdido en el olvido, y que supone el cierre de la saga.\"John Rambo\" nos muestra la contemplativa vida que disfruta tan conocido personaje en su avanzada edad, dedicándose a pescar, coger serpientes para un espéctaculo típico de demostraciones de ese tipo y vagar sin rumbo fijo por los ríos de algún rincón perdido cerca de la selva Birmana. Cuando llegan un grupo de americanos con la intención de remontar el río para dar ayuda humanitaria y médica a un poblado birmano, la primera reacción de Rambo es avisarles que no es una buena idea, y negarse a ello en rotundo. Finalmente, por la intervención de una mujer (quién sino) que acompaña el grupo de ayuda humanitaria, Rambo accede a llevarles río arriba y dejarles allí, con la intención de volver por ellos mismos tierra adentro. Cuando el plan se tuerce y son capturados por la sección más radical del ejército opresor Birmano, un grupo de mercenarios, en colaboración con Rambo (aunque en principio su oposición a ello era evidente), se dispone a rescatarlos de aquella barbarie que se vive día a día en las selvas birmanas.Stallone se encarga, en sus labores como director, de insuflar un estilo visual recargado, opresivo, tan del gusto del género bélico más extremo, en una puesta en escena en la cual demuestra (al igual que ya hizo en \"Rocky Balboa\") una solvencia a tener en cuenta cuando se trata de filmar escenas de acción. Escenas como la que abre el film, con ese juego macabro por parte del ejercito birmano, demuestran que cuanto menos sabe como hacer creible y cercano un hecho terrible, sin artificios, de forma seca y directa. No se produce en ningún momento un juego creativo entre imagen y director más allá de hacer avanzar la narración, pero no por ello resulta menos eficaz. También es cierto que el guión del film resulta tremendamente plano, carente de dobles lecturas más que evidentes referencias al horror de la guerra, y frases que resultan bastante ridículas como que nuestro querido Rambo nos aleccione con perlas como \"vivir por nada, o morir por algo\", que verdaderamente provocan más la risa sarcástica que el efecto dramático que pretendía. Y aunque es cierto que ese libreto, por lo que se intuye, deja muchísimo que desear, al menos la historia se desarrolla de manera bastante directa, sin recurrir a giros de guión que aún hagan más evidente las carencias de este producto de acción descerebrado.Y es que además, el apartado actoral es de un tópico que asusta, quitando pequeños matices de la actriz de la función, Julie Benz (conocida básicamente por ser el objeto de deseo de Dexter, en la serie de mismo nombre), que sabe dotar de un cierto interés el dilema moral y el sufrimiento que los horrores de la guerra provocan en ella. Del resto, curiosamente destacar el grado de nihilismo absoluto, por encima del bien y del mal , que ha adquirido Rambo como personaje, estando en esta ocasión correcto para lo que suponía su \"ausente\" actuación. Las demás caracterizaciones de personajes son todas prototipos de personajes ya vistos mil veces en el cine bélico, con un grupo de mercenarios que recuerda a cualquier producción similar del género (algún personaje recuerda de manera irremediable a ciertos personajes de aquella estupenda \"Depredador\"), y que además, no parecen esforzarse mucho por hacerlo mejor.Con todos estos elementos, uno podría pensar que el producto final es un despreciable subproducto destinado a consumidores de video directo, o amantes de la acción menos exigente. Pero no es precisamente el caso de \"John Rambo\". Y si no es asi, es precisamente por la habilidad antes comentada de Stallone para crear escenas de acción verdaderamente eficaces, violentas hasta el extremo, en un alarde de incorreción que recuerda irremediablemente al cine ochentero, aquel que obviaba toda consideración visual para mostrarnos escenas a cual más violenta.Stallone se encarga de ofrecernos un festín de desmembramientos, amputaciones, sangre a borbotones, explosiones varias e incluso violaciones infantiles, que provocan un efecto sorpresa en el espectador por lo atípico de la propuesta en el cine actual de género. Con respecto a este tema, aclarar un par de puntos importantes sobre exaltación de la violencia como conductora del relato. Demuestra una tremenda habilidad para sortear contratiempos en forma de inexistentes coreografías mediante precisamente esa orgía de sangre que suponen las habilmente distribuidas escenas de acción a lo largo del metraje, camufla con habilidad su avanzada edad y su escasa capacidad de coreografiar las escenas, con momentos de salvajismo paroxista, en un truco argumental que le funciona, y que deja una sensación de film de privilegiadas escenas de acción (cuando un análisis a fondo, o incluso un segundo visionado dejarán en evidencia esas supuestas escenas, que son más sencillas de lo que parecen). Es de agradecer de todas formas, que la ideología reaccionaria brille por su ausencia, resultando Rambo aún menos apegado a ningún tipo de ideología al respecto, porque ayuda a que dichas escenas de acción se justifiquen más por la empatía hacia una mujer que por cualquier otra cosa (si obviamos sus alucinados pensamientos sobre su incapacidad para desprenderse de la guerra como algo inherente, que son tremendamente estúpidos a todas luces).El otro punto que domina esas eficaces escenas de acción, es el montaje. Es evidente que en el cine americano predomina hacer avanzar las escenas de acción mediante el nivel de habilidad por parte del montador en dichas escenas. En este caso, permite no solo apuntalar el truco ese utilizado por Stallone de distribuir eficazmente escenas de acción que parecen más físicas de lo que son, sino que además enriquece y da alas al significado de esas escenas, haciéndolas integrarse en el relato de manera harto eficaz. Un montaje sin duda muy acertado y que contribuye a crear la ilusión de escenas de acción de profundo calado. No opta, por ejemplo, por la capacidad impecable de situar la acción que normalmente posee el cine asiático, sino por hacer avanzar la acción física mediante un gran montaje visual. Tremendamente habilidoso y solvente, sin duda.Decir que las influencias de las cuales bebe el film son múltiples y de lo más variado, acudiendo incluso al propio sentimiento autoreferencial durante gran parte de la historia, además de recordar en su extrema violencia a films como la saga hongkonesa de \"Men behind the Sun\", con sus atrocidades varias cometidas por enfermizos generales asiáticos.Como resultado, un film que pese a un guión plano, unas interpretaciones mediocres y un desarrollo tópico, consigue alcanzar la virtud de la diversión mediante unas primorosas escenas de acción, repletas de descarnada y apolítica violencia. Para fanáticos de la acción menos exigente.</td>\n",
       "      <td>Un film que pese a un guión plano, unas interpretaciones mediocres y un desarrollo tópico, consigue alcanzar la virtud de la diversión mediante unas primorosas escenas de acción, repletas de descarnada y apolítica violencia.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hay dos tipos de personas en el mundo, los que son fans de los Beatles y \"el resto\". Por eso era cuestión de tiempo que alguien decidiera que era una brillante idea hacer un musical que usase las mejores canciones del mejor grupo musical de la historia como hilo conductor de una película que toma su título de una grabación de 1968 realizada con fines benéficos. Obviamente y como no podía ser de otra manera está ambientada en los sesenta. Jude, un joven trabajador de los astilleros de Liverpool decide salir de su Inglaterra natal para buscar una vida mejor en Estados Unidos. Desde luego la música será una parte fundamental de su nueva vida en Nueva York. Encontrará sus ideales, se enfrentará con los fantasmas de la época: Vietman, las drogas, el amor, la vida,.. esos temas que siempre se ven mucho mejor tras una velo de psicotrópicos.La película es deliciosa y arriesgada. Actores prácticamente desconocidos acompañados en la pantalla por los grandes de la música comprometidos, ¿Qué sería de una película a favor de la paz y el dialogo sin Bono cantando en ella?, ¿Qué mayor placer que Joe Cocker cantando en el metro?, ¿Qué hombre no ha fantaseado con Salma Hayek a lo Pin up multiplicada por seis?, Todo ellos bien condimentado da a Across The Universe una trepidante base y un comienzo explosivo. Posiblemente ese ritmo se vea roto con el viaje psicodélico en el autobús y en la estética surrealista del circo (desde mi punto de vista el único punto totalmente prescindible).Across The Universe me ha encantado porque conserva intacto el espíritu conciliador de la época y da un toque personal a las canciones del mítico grupo. Los actores son sencillamente magníficos y Jim Sturgess es la revelación del año con un delicioso acento y una voz cálida y entusiasta saltando desde producciones televisivas de categoría inferior directamente a la primera división.Para todos aquellos que han vivido la época de The Fab Four, para los nostálgicos sesenteros y para los pacifistas declarados es de obligatorio visionado.</td>\n",
       "      <td>Para todos aquellos que han vivido la época de The Fab Four, para los nostálgicos sesenteros y para los pacifistas declarados es de obligatorio visionado.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Antes de entrar en materia me gustaría dejar claro que no tengo nada contra la realización de remakes. Es un fenómeno que se produce desde el comienzo del cine y que no va a dejar de producirse precisamente ahora que la imaginación brilla por su ausencia. Dicho eso, creo que lo mínimo que se le puede exigir a un remake es una mirada diferente a la misma historia o bien una actualización de los elementos originales. Es decir, ya que vamos a hacer lo mismo que hicieron otros antes, al menos hagámoslo de otra forma.Por eso, pese a que ya hay dos versiones anteriores realmente buenas y que podría parecer ya excesiva la realización de una cuarta versión del mismo asunto, la elección de Oliver Hirschbiegel como director daba la sensación de estar motivada por la búsqueda de un nuevo enfoque a la historia.No sé si sería por lo novedoso del enfoque de Hirschbiegel pero el caso es que, una vez finalizado su montaje, los productores decidieron contratar a los hermanos Wachowski para hacer algunos cambios en el guión y a James McTeigue para dirigir escenas adicionales. Entre otras un cambio total del final y unas cuantas escenas de acción (suena mal, sí).Desconozco como sería el montaje inicial de Hirschbiegel pero cambiarlo, por haber hecho algo diferente, no me parece una buena idea. Este tipo de cosas no suelen funcionar y esta vez no iba a ser diferente.Porque si un problema tiene \"Invasión\" (The invasion) es que es más de lo mismo. Tanto me da si son aliens como si son zombies, la escena de la protagonista escapando desesperada de una horda de monstruos humanoides que corren como el diablo, empiezo a tenerla muy vista.De poco sirve que Nicole Kidman y Daniel Craig estén a la altura de lo esperado en ellos, porque el fallo de la peli es no tener alma. Se le nota demasiado que ha sido remontada y el resultado final es totalmente desequilibrado y está rematado con cierta torpeza.Da la sensación de que la idea del asunto era reflexionar sobre si la pérdida de nuestra humanidad es un precio demasiado alto a pagar a cambio de no tener guerras o pobreza (impagable ver a Bush dándole la mano a Chavez) pero esa reflexión se deja caer sin profundizar lo más mínimo en ella, como con intención de darle a la película un empaque filosófico del que, en realidad, carece.Es curioso que \"la primera de las versiones\" tenga ya más de 50 años y sea mucho más audaz y tenga un mensaje más radical que la película que nos ocupa.En el lado positivo cabe mencionar que la película es entretenidilla y el aburrimiento no llega a apoderarse del espectador. Claro que éste es un pobre consuelo para quien decida gastarse 6 euros en la entrada del cine.</td>\n",
       "      <td>Es más de lo mismo. Tanto me da si son aliens como si son zombies, la escena de la protagonista escapando desesperada de una horda de monstruos humanoides que corren como el diablo, empiezo a tenerla muy vista.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Repaso The Birthday, la peli de Eugenio Mira, y me lo paso en grande. Tengo que reconocer que cuando la vi por primera vez estaba virgen (muy muy muy virgen) y me saturó tanto para bien como para mal.Vista la edición editada en dvd por Versus (re)descubro una película intensa, imaginativa y absolutamente delirante llena de planos secuencias, personajes estrambóticos, Lynch, Scifi50's y apurando un poco hasta Buñuel. Pero apurando.Todas esas referencias le dan la atmósfera perfecta al film, tan creíble como la de Donnie Darko amén de recuperar para la gran pantalla a Corey Feldman, una razón de peso para no dejar escapar la película ahora que la podemos comprar en El Corte Inglés.Una deliciosa locura a la que se le agradece poder verla en casa porque recuerdo el clímax en la sala de cine con el volumen a todo trapo y aún me duelen los oídos. El plano final es una gozada.PD: Creo recordar que la versión que proyectaron en la muestra del Palafox era en tiempo real. No olvidemos que la peli son los 117 minutos más raros de la vida de Norman Forrester. El dvd se queda en un correcto \"cut\" de 96'.</td>\n",
       "      <td>Lynch, SciFi \"de tó la vida\" y mucha mala hostia en una peli lamentablemente maldita dentro del cine español. Un delirio que necesita un espectador dispuesto a dejarse llevar.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chris Columbus aportó a las dos primeras entregas de \"Harry Potter\" un halo mágico, de libros infantiles (no podía ser para menos, ya que los dos primeros libros asi eran), luego vino Alfonso Cuarón y transformó la saga de Potter en una cinta oscura y plagada de claroscuros, sin embargo Mike Newell transforma la saga en una mera comedieta romántica (no podía ser para menos, el director británico es el \"autor\" de películas como \"4 Bodas y un funeral\" o \"La sonrisa de Mona Lisa\").No puedo negar que la película me ha gustado, bastante, para que engañarnos, y sin embargo, esperaba algo más, un gran libro del que no han sabido plasmar ni la mitad, se comen cosas que serán importantes e intentan meter con calzador otras que son carne del quinto libro (también quinta película), los interpretes, como siempre, al trío protagonista ya se les nota cómodos en sus respectivos papeles y tal vez, habría que centrar la atención a los debutantes que aunque lo hacen bastante bien no están a la altura de sus compañeros de reparto.Los dos mejores de la película, sin duda, son Brendan Gleeson (como \"Ojoloco Moody\") y Ralph Fiennes (\"Como Voldemort\") aunque tal vez a este último me le imaginaba bastante más peligroso que como nos lo muestran en pantalla.Resumiendo; si bien la película es bastante buena, no consigue plasmar al 100 % uno de los libros más largos y con más \"miga\" de la saga de Potter, recomiendo no ir con todas las esperanzas puestas en la película o la decepción podría ser enorme.</td>\n",
       "      <td>Si bien la película es bastante buena, no consigue plasmar al 100 % uno de los libros más largos y con más \"miga\" de la saga de Potter.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Walt Disney necesita reverdecer su prestigio, perdido ( en parte ) por los méritos de Pixar ( John Lasseter a la cabeza ) y la factoría Dreamworks ( con Steven Spielberg a los mandos ). No va a ser ésta la cinta que regurgite la fama fugada, pero da un rato entretenido ( de eso se trata ) y contentará a quienes asisten al cine para disfrutar con hora y media de evasión honesta.Descubriendo a los Robinsons viene a ser un manual de autoayuda camuflado de largometraje de animación. Como si Paulo Coelho ( ese malabarista de los solucionarios sentimentales, ese gurú impostado que vende como galletas de coco sus prontuarios para necesitados ) hubiese metido el dedo en el guión y aportase su muy particular visión de la sentimentalidad humana.Gusta ( y mucho ) por partes : está muy lograda y se ve con golosa delectación en un primer momento, cuando se plantea el nudo de la trama, esto es, el niño huérfano que quiere una familia y termina en el futuro descubriendo a los Robinsons, una familia excéntrica, convulsa, sobrevitaminada de esteroides esterales o, si se quiere, sencillamente escrito, loca de atar. La película se ve sin desagrado, no cansa, produce ( todo sea dicho ) cierta sensación de deja vu, como si todo ya lo hubiésemos visto en otras películas de adultos, pero aquí la Disney pone su visión correcta de la familia, que es la que siempre le ha dado los cuartos, y produce un film correcto, sin más, que no pasará a la historia de la firma y tampoco a la memoria del espectador. Niños incluídos.Además, finiquitando, se enrevesa todo mucho, se espesa.El tiempo, juez severo, la colocará en su lugar, en su anaquel de productos de alquiler fácil de videoclub de barrio en esas tardes empalagosas de calor que ya van principiando el verano.</td>\n",
       "      <td>Directa al DVD. No hay más. Y ahí arrasará. Disney tiene estos requiebros del destino, su filón para continuar la leyenda.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4d8facc-f0c7-421d-9649-f37b117c9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ce0be23-e68e-46af-bca1-d215576fb779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[\"train\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb2b178e-2cbe-423c-93b6-88836c85b096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STALLONE parecía abocado al olvido tras fracas...</td>\n",
       "      <td>El filme da lo que se espera de el sin floritu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buena película de Gerardo Olivares, que hace b...</td>\n",
       "      <td>Muy interesante drama social, que hace reflexi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woody Allen es un grande del cine de todos los...</td>\n",
       "      <td>Desprende tal tufillo a telefilm, que difícilm...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qué raro. Porque no hablamos de un blockbuster...</td>\n",
       "      <td>Una película bonita y discreta, con hallazgos ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Si ya lo decía yo, nada bueno sale del híbrido...</td>\n",
       "      <td>No es una película de Jack Black, sino de Jare...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  \\\n",
       "0  STALLONE parecía abocado al olvido tras fracas...   \n",
       "1  Buena película de Gerardo Olivares, que hace b...   \n",
       "2  Woody Allen es un grande del cine de todos los...   \n",
       "3  Qué raro. Porque no hablamos de un blockbuster...   \n",
       "4  Si ya lo decía yo, nada bueno sale del híbrido...   \n",
       "\n",
       "                                      review_summary  star_rating  \n",
       "0  El filme da lo que se espera de el sin floritu...            3  \n",
       "1  Muy interesante drama social, que hace reflexi...            3  \n",
       "2  Desprende tal tufillo a telefilm, que difícilm...            2  \n",
       "3  Una película bonita y discreta, con hallazgos ...            3  \n",
       "4  No es una película de Jack Black, sino de Jare...            1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab53e911-2374-4ed9-8763-8824ab105d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    936\n",
       "2    695\n",
       "4    665\n",
       "5    352\n",
       "1    256\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"star_rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe2083-e959-446a-a831-90139c8ebbe4",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa254bb-162f-44e4-9b40-595a90ad220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_checkpoint = \"bertin-project/bertin-roberta-base-spanish\"\n",
    "model_checkpoint = \"BSC-TeMU/roberta-base-bne\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55cfde4b-6b30-4942-b664-fdb86af23ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50262"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e3fb069-14cd-4d01-814c-be1434d8b130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8edd6d92-bc62-4bfc-bebf-0ce4713dfa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <s>\n",
      "1465 ¡\n",
      "12616 hola\n",
      "66 ,\n",
      "503  me\n",
      "17111  llamo\n",
      "532  le\n",
      "19514 wis\n",
      "55 !\n",
      "2 </s>\n"
     ]
    }
   ],
   "source": [
    "encoded_str = tokenizer.encode(\"¡hola, me llamo lewis!\")\n",
    "\n",
    "for token in encoded_str:\n",
    "    print(token, tokenizer.decode([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed3a5337-be51-4b63-a48f-d84469ea63e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.9.2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1543d6d4-0ca0-436b-afd6-1f099d5c9bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 1465, 12616, 66, 503, 17111, 532, 19514, 55, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"¡hola, me llamo lewis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff247495-66e6-4d5b-a929-5a918eb1e8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 12616, 55, 2], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"hola!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0968cab8-83a7-4f31-8cad-096915fb55ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' administrativo'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(11884)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2cb34ef-0172-4a15-8b8e-19c7408acab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 <s>\n",
    "# 1922 ¡\n",
    "# 11884 hola\n",
    "# 16 ,\n",
    "# 378  me\n",
    "# 13496  llamo\n",
    "# 466  le\n",
    "# 91 w\n",
    "# 350 is\n",
    "# 5 !\n",
    "# 2 </s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c6610f-c622-41e0-8c78-695a9f2cec82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_len_single_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5ab78b5-f8d7-4701-98d5-42a7bb9cc677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples[\"review_body\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50afcb76-51f0-4691-900f-74e9ed6e5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f22d9b1f-777b-40e1-ba62-7e3acd5fb6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 56, 20211, 66, 1486, 5624, 499, 737, 4545, 11962, 347, 405, 313, 3319, 5256, 341, 683, 12757, 341, 344, 3505, 403, 1190, 2690, 47739, 313, 10846, 334, 405, 2266, 375, 405, 1361, 9925, 334, 332, 1611, 68, 951, 3505, 342, 332, 14950, 361, 4090, 1204, 467, 2638, 313, 2070, 66, 313, 332, 2132, 66, 313, 1242, 22471, 342, 796, 320, 1979, 41978, 10887, 47260, 68, 3959, 6481, 1912, 344, 7466, 80, 332, 29322, 31290, 1700, 313, 2070, 68, 1267, 956, 993, 313, 2070, 733, 355, 1652, 37128, 26752, 342, 1242, 15917, 332, 369, 2125, 835, 16250, 355, 12141, 1208, 375, 405, 4098, 1078, 68, 6918, 1577, 66, 6668, 6305, 49343, 4360, 66, 683, 7162, 15432, 405, 1397, 15001, 13271, 473, 336, 580, 2036, 66, 48192, 711, 344, 3549, 63, 588, 405, 2704, 727, 21907, 320, 3319, 1312, 7557, 341, 3522, 38054, 320, 1180, 4933, 68, 859, 27001, 725, 313, 332, 3884, 66, 332, 6249, 24485, 313, 332, 5062, 313, 39352, 2449, 66, 1487, 13739, 9447, 313, 1180, 4545, 66, 1242, 9242, 332, 369, 2650, 68, 547, 383, 1337, 341, 683, 1295, 1227, 334, 355, 5366, 313, 24112, 342, 403, 334, 355, 5366, 313, 2776, 4689, 350, 11777, 467, 7172, 341, 387, 370, 5203, 313, 459, 454, 36654, 8115, 313, 18086, 7258, 56, 342, 10496, 314, 2935, 312, 27112, 6092, 2449, 350, 27458, 313, 33932, 342, 8190, 313, 30209, 68, 1267, 533, 5366, 683, 6552, 350, 4916, 961, 816, 8031, 342, 313, 6706, 342, 21244, 68, 6300, 1998, 705, 477, 66, 14027, 312, 2035, 727, 14621, 741, 68, 473, 496, 14093, 313, 3959, 334, 344, 28306, 334, 935, 6140, 403, 819, 33226, 63, 6955, 1430, 40435, 334, 4596, 389, 5947, 313, 3959, 66, 21289, 350, 11219, 35218, 342, 8010, 383, 27487, 27016, 1019, 341, 8750, 3078, 355, 5947, 341, 361, 683, 2907, 44272, 342, 4427, 68, 859, 8978, 347, 466, 5951, 727, 4534, 342, 683, 13163, 383, 2683, 355, 5915, 341, 14267, 2578, 9150, 623, 341, 2090, 683, 16717, 1347, 68, 859, 8049, 341, 9065, 3959, 342, 332, 38662, 919, 25340, 392, 1929, 355, 4658, 588, 21690, 2258, 66, 9008, 383, 7232, 313, 1122, 405, 2250, 313, 4661, 342, 10308, 727, 961, 1271, 3932, 342, 20698, 3638, 2475, 2449, 341, 2029, 5150, 342, 1506, 22611, 332, 9035, 1611, 369, 3505, 68, 1541, 347, 405, 3021, 341, 24603, 663, 5333, 1038, 394, 5166, 1292, 313, 935, 12147, 1754, 1224, 387, 3295, 313, 373, 4141, 66, 394, 1278, 5289, 1429, 3379, 467, 3994, 313, 935, 361, 21234, 399, 3094, 1388, 68, 1267, 373, 920, 44803, 122, 3622, 781, 144, 66, 4247, 383, 4914, 1764, 738, 727, 4915, 350, 529, 25889, 342, 383, 370, 6355, 421, 313, 364, 18661, 9131, 394, 6346, 3238, 364, 12175, 4540, 66, 683, 31233, 459, 20867, 320, 332, 1530, 313, 31565, 56, 473, 32253, 848, 473, 1933, 9413, 2408, 320, 373, 1229, 5435, 342, 8496, 459, 1967, 38407, 14462, 56, 473, 29673, 63, 341, 819, 1204, 341, 664, 350, 514, 68, 1267, 1871, 66, 344, 5560, 3622, 781, 144, 66, 5676, 823, 313, 892, 20020, 342, 15042, 66, 344, 2], [0, 539, 665, 355, 26696, 341, 1162, 7889, 3021, 341, 1840, 344, 2515, 28987, 313, 405, 892, 355, 1109, 28594, 66, 2514, 7225, 334, 2682, 17257, 342, 350, 332, 4068, 1622, 375, 1258, 466, 38614, 66, 683, 8529, 405, 2086, 466, 459, 3346, 329, 10239, 46595, 671, 859, 3021, 313, 15029, 143, 24958, 67, 1288, 137, 329, 66, 2422, 66, 313, 332, 1806, 892, 66, 502, 413, 955, 1977, 342, 26284, 2971, 313, 332, 17989, 42639, 66, 623, 442, 341, 9242, 334, 1871, 347, 344, 3612, 4840, 473, 6380, 21293, 403, 7351, 320, 4905, 7082, 66, 1520, 389, 2276, 369, 1077, 63, 313, 332, 4068, 68, 111, 347, 313, 10499, 647, 341, 66, 383, 3160, 7910, 32487, 341, 2178, 26950, 334, 9310, 4327, 473, 10857, 665, 334, 332, 36727, 313, 364, 10727, 848, 344, 13333, 361, 2907, 4380, 553, 15662, 801, 68, 1126, 1305, 347, 66, 5607, 66, 344, 1021, 313, 529, 14621, 3221, 68, 9356, 320, 341, 364, 6298, 6058, 313, 1658, 350, 10464, 18694, 3118, 375, 1977, 66, 22452, 66, 17040, 375, 29820, 66, 332, 2307, 342, 373, 1906, 403, 361, 2514, 11976, 334, 3094, 9745, 334, 2460, 68, 44665, 12704, 313, 17570, 342, 48650, 334, 332, 3031, 313, 332, 1952, 341, 3298, 796, 6533, 14413, 66, 1351, 383, 332, 3913, 341, 1351, 68, 1126, 1317, 347, 442, 341, 16565, 344, 13333, 80, 6492, 344, 3475, 313, 387, 4326, 313, 364, 1573, 372, 30401, 321, 68, 37343, 403, 26482, 355, 1450, 7826, 341, 683, 10251, 2296, 344, 383, 1350, 313, 1577, 68, 43779, 2121, 341, 499, 6645, 313, 27104, 334, 373, 3923, 342, 4891, 313, 41187, 68, 4778, 66, 383, 1204, 341, 1660, 361, 9752, 31343, 334, 8020, 442, 3908, 66, 403, 3536, 7910, 760, 25651, 334, 344, 1246, 313, 8810, 9345, 387, 4326, 313, 3322, 66, 1351, 1573, 372, 33860, 66, 2161, 521, 375, 1783, 319, 730, 473, 523, 344, 8486, 1915, 313, 332, 738, 3434, 24602, 459, 454, 1165, 385, 521, 19135, 608, 734, 66, 350, 1577, 403, 361, 3907, 8022, 344, 1246, 313, 12726, 610, 68, 43077, 341, 3560, 442, 13048, 46731, 466, 394, 8521, 3063, 68, 6236, 347, 4534, 342, 16113, 8017, 334, 332, 3923, 313, 3322, 66, 4458, 9345, 371, 342, 7585, 529, 21905, 342, 5209, 529, 43936, 2935, 66, 383, 727, 50178, 341, 1351, 344, 10808, 341, 380, 10406, 68, 448, 18581, 66, 342, 1411, 342, 466, 15689, 66, 383, 1915, 66, 334, 459, 454, 584, 1181, 1115, 669, 403, 665, 344, 1077, 1355, 4555, 313, 8017, 334, 332, 3923, 313, 355, 23818, 466, 19830, 473, 137, 421, 1315, 466, 22349, 946, 3173, 1447, 1484, 2038, 356, 9398, 1723, 350, 1417, 40432, 68, 1126, 442, 4479, 9345, 68, 16260, 320, 405, 1952, 350, 19009, 22180, 532, 33170, 727, 16113, 66, 342, 66, 320, 655, 313, 4188, 66, 342, 1334, 35239, 37742, 66, 334, 1317, 361, 9903, 332, 22868, 68, 1267, 403, 853, 34582, 313, 2402, 1373, 68, 12826, 2129, 1880, 313, 341, 683, 3189, 1120, 313, 341, 387, 4080, 403, 644, 387, 15104, 6298, 68, 951, 47990, 66, 313, 6760, 892, 66, 1190, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text(dataset[\"train\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc083152-d33e-4215-aa55-6c0f34843014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/lewis/.cache/huggingface/datasets/muchocine/default/1.1.1/3ed5582584cd84ef722606a3d725ef18fd4647d63195fef05c47683e5a056ccd/cache-0849cda84c312499.arrow and /home/lewis/.cache/huggingface/datasets/muchocine/default/1.1.1/3ed5582584cd84ef722606a3d725ef18fd4647d63195fef05c47683e5a056ccd/cache-233b7aca96264eb3.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset[\"train\"].train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48c07922-100f-40b5-8b45-87448bde2f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b216c2b6a284fd0bc97f91de3da2a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3004421e692e431182f9149fdbb099a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(tokenize_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff98a5b1-6415-4d7e-ba47-7d89ce7ebfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at BSC-TeMU/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at BSC-TeMU/roberta-base-bne and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels = 5\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4ebab1c-893c-4eb9-8f51-9e55c6596463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\") \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75fc4131-7a48-42bb-b9a7-f8df40a05aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 16\n",
    "logging_steps = len(encoded_dataset[\"train\"]) // batch_size\n",
    "training_args = TrainingArguments(output_dir=\"results\",\n",
    "                                  num_train_epochs=5,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\",\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17a16c06-2c30-4fcf-b67c-cdb77639effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = encoded_dataset.rename_column(\"star_rating\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97115764-8db1-4613-9b51-9f96a2b51fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1, 4, 5]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"].unique(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b90c6b6-f440-4775-99fe-7ad5fa20ea2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c115807-61e9-4ba2-a100-df2ac2266767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: review_summary, review_body.\n",
      "***** Running training *****\n",
      "  Num examples = 2904\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 455\n",
      "/home/lewis/miniconda3/envs/hf/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "transform: failed to synchronize: cudaErrorAssert: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-55ea2dd6476d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   tokenizer=tokenizer)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1284\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: transform: failed to synchronize: cudaErrorAssert: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=encoded_dataset[\"train\"],\n",
    "                  eval_dataset=encoded_dataset[\"test\"],\n",
    "                  tokenizer=tokenizer)\n",
    "\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b140f30c-12f9-4caf-b59c-2b57f9122b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: review_summary, review_body.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 968\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f245b31d31e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2042\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m             \u001b[0;31m# Update containers on host\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   2375\u001b[0m         \"\"\"\n\u001b[1;32m   2376\u001b[0m         \u001b[0mhas_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_keys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_deepspeed_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                 \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_past\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c503d0d-699a-4f26-a093-bea61f03d3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
