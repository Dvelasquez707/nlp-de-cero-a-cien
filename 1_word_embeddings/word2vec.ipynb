{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7jhPCMfOPIOUPgJ0uXlFK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlp-en-es/nlp-de-cero-a-cien/blob/main/1_word_embeddings/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvNCXd9Dfqe1"
      },
      "source": [
        "# Word2vec con Gensim\n",
        "\n",
        "En este cuaderno de Jupyter vas a utilizar la biblioteca [Gensim](https://radimrehurek.com/gensim/index.html) para experimentar con word2vec. Este cuaderno está enfocado en la intuición de los conceptos y no en los detalles de implementación. Este cuaderno está inspirado en esta [guía](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html).\n",
        "\n",
        "## 1. Instalación y cargar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKIqnDXXfpiz",
        "outputId": "56d63e94-fac5-4a2d-d166-ecb062af0bea"
      },
      "source": [
        "!pip install --upgrade gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/52/f1417772965652d4ca6f901515debcd9d6c5430969e8c02ee7737e6de61c/gensim-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (23.9MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9MB 127kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn7Q2jB3frOn",
        "outputId": "c82c2447-08eb-49b5-a491-67aaedc6d36a"
      },
      "source": [
        "import gensim.downloader as api"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBaT8djWkaZy"
      },
      "source": [
        "model = api.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVZm7iTOoawW"
      },
      "source": [
        "## 2. Similitud de palabras\n",
        "\n",
        "En esta sección veremos cómo conseguir la similitud entre dos palabras utilizando un word embedding ya entrenado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOZfaelLoi4c",
        "outputId": "b76e7b63-8a44-4492-df63-2d1747e5706c"
      },
      "source": [
        "model.similarity(\"king\", \"queen\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6510957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX-Kk9HZofuF",
        "outputId": "329c0f4b-d5d8-4782-b45e-8f66aba6d7fd"
      },
      "source": [
        "model.similarity(\"king\", \"man\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22942673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypFK-pLrol3N",
        "outputId": "10a164af-07cc-47c7-b496-e233031f1bf4"
      },
      "source": [
        "model.similarity(\"king\", \"potato\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09978465"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBWzZySFormq",
        "outputId": "d620b25b-a0f5-4aad-8729-fc00c567a60b"
      },
      "source": [
        "model.similarity(\"king\", \"king\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GijWs_tx83W"
      },
      "source": [
        "Ahora veremos cómo encontrar las palabras con mayor similitud al conjunto de palabras especificado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytELAWBLk2-6",
        "outputId": "c6f118c6-07ac-4dfc-e0c8-634690c3b706"
      },
      "source": [
        "model.most_similar([\"king\", \"queen\"], topn=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('monarch', 0.7042067050933838),\n",
              " ('kings', 0.6780861616134644),\n",
              " ('princess', 0.6731551885604858),\n",
              " ('queens', 0.6679497957229614),\n",
              " ('prince', 0.6435247659683228)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D4ZS7N3ovxB",
        "outputId": "6a4a84e0-b1cf-48e4-bddf-5bc7b7a0c53d"
      },
      "source": [
        "model.most_similar([\"tomato\", \"carrot\"], topn=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('carrots', 0.7536594867706299),\n",
              " ('tomatoes', 0.7129638195037842),\n",
              " ('celery', 0.7025030851364136),\n",
              " ('broccoli', 0.6796350479125977),\n",
              " ('cherry_tomatoes', 0.662927508354187)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZFlxKjOyBpu"
      },
      "source": [
        "Pero incluso puedes hacer cosas interesantes como ver qué palabra no corresponde a una lista."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8CrZdcBpn3pn",
        "outputId": "dc5283b9-066c-4ac2-cd1f-4408279102bb"
      },
      "source": [
        "model.doesnt_match([\"summer\", \"fall\", \"spring\", \"air\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'air'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko09hZ3dqMZ1"
      },
      "source": [
        "## Ejercicios\n",
        "\n",
        "1. Usa el modelo word2vec para hacer un ranking de las siguientes 15 palabras según su similitud con las palabras \"man\" y \"woman\". Para cada par, imprime su similitud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzZ1eD3PpT-d"
      },
      "source": [
        "words = [\n",
        "\"wife\",\n",
        "\"husband\",\n",
        "\"child\",\n",
        "\"queen\",\n",
        "\"king\",\n",
        "\"man\",\n",
        "\"woman\",\n",
        "\"birth\",\n",
        "\"doctor\",\n",
        "\"nurse\",\n",
        "\"teacher\",\n",
        "\"professor\",\n",
        "\"engineer\",\n",
        "\"scientist\",\n",
        "\"president\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKamywnxqxJJ"
      },
      "source": [
        "**2. Completa las siguientes analogías por tu cuenta (sin usar el modelo)**\n",
        "\n",
        "a. king is to throne as judge is to _\n",
        "\n",
        "b. giant is to dwarf as genius is to _\n",
        "\n",
        "c. French is to France as Spaniard is to _\n",
        "\n",
        "d. bad is to good as sad is to _\n",
        "\n",
        "e. nurse is to hospital as teacher is to _\n",
        "\n",
        "f. universe is to planet as house is to _"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcNRxHuZrXAM"
      },
      "source": [
        "**3. Ahora completa las analogías usando un modelo word2vec**\n",
        "\n",
        "Aquí hay un ejemplo de cómo hacerlo. Puedes resolver analogías como \"A es a B como C es a _\" haciendo A + C - B. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4kF08h4qhxM",
        "outputId": "49a14994-cc39-4b9b-8141-877886d7a55e"
      },
      "source": [
        "# man is to woman as king is to ___?\n",
        "model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118193507194519)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiPbbGsori48",
        "outputId": "c084177b-3459-4efd-b844-45586646c369"
      },
      "source": [
        "# us is to burger as italy is to ___?\n",
        "model.most_similar(positive=[\"Mexico\", \"burger\"], negative=[\"USA\"], topn=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('taco', 0.6266060471534729)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocZO0Ma3xQfb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}